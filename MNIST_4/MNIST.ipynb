{"cells":[{"metadata":{"_uuid":"427ce49fba02f44de9e3081288fca2da38e51140","_cell_guid":"56682ac8-509e-44fb-a694-4bf1082d36d2","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\n\nimport math\nimport random\n\nfrom PIL import Image, ImageOps, ImageEnhance\nimport numbers\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86cafb6770a21e6ed806c17c2be9897399bdf520","_cell_guid":"5b89951b-5acb-4957-b6e4-cfeb54f4a053","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\n\nn_train = len(train_df)\nn_pixels = len(train_df.columns) - 1\nn_class = len(set(train_df['label']))\n\nprint('Number of training samples: {0}'.format(n_train))\nprint('Number of training pixels: {0}'.format(n_pixels))\nprint('Number of classes: {0}'.format(n_class))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c697381fd6210380e2350553bd43ca13194cff1","_cell_guid":"7bf732ab-a5e7-4db0-ab30-8b3f1f89bf60","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')\n\nn_test = len(test_df)\nn_pixels = len(test_df.columns)\n\nprint('Number of train samples: {0}'.format(n_test))\nprint('Number of test pixels: {0}'.format(n_pixels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cfd978d90f8fe48bf7494a2e00448c3ec48b05b","_cell_guid":"969c8fd1-72b0-46a8-af7c-62f630f626e8","trusted":true},"cell_type":"code","source":"random_sel = np.random.randint(n_train, size=8)\n\ngrid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].to_numpy()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16, 2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')\nprint(*list(train_df.iloc[random_sel, 0].values), sep = ', ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2aad956c1baa1e29a259902835b66b020a540c96","_cell_guid":"ecd233dc-e143-4964-87db-21b8aa8a192c","trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (8, 5)\nplt.bar(train_df['label'].value_counts().index, train_df['label'].value_counts())\nplt.xticks(np.arange(n_class))\nplt.xlabel('Class', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.grid('on', axis='y')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13401816f84176712146c336d11bdab8ce549bce","_cell_guid":"711ee835-cb44-4243-9f7e-60c6c4301cca","trusted":true},"cell_type":"code","source":"class MNIST_data(Dataset):\n    \"\"\"MNIST dtaa set\"\"\"\n    \n    def __init__(self, file_path, \n                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n                ):\n        \n        df = pd.read_csv(file_path)\n        \n        if len(df.columns) == n_pixels:\n            # test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            # training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n            \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f6e6b26a71c7ca9fc3126265ad8d27491a849f5","_cell_guid":"d0e41412-1be1-4ca6-a5f8-d7839d2e7010","trusted":true},"cell_type":"code","source":"batch_size = 64\n\ntrain_dataset = MNIST_data('../input/train.csv')\ntest_dataset = MNIST_data('../input/test.csv')\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                           batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"875f53c04b120b40cd695c57a774165259183413","_cell_guid":"766abaee-5811-4963-a4ac-69d910d9eead","trusted":true},"cell_type":"code","source":"class Net(nn.Module):    \n    def __init__(self):\n        super(Net, self).__init__()\n          \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n          \n        self.classifier = nn.Sequential(\n            nn.Dropout(p = 0.5),\n            nn.Linear(64 * 7 * 7, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 10),\n        )\n          \n        for m in self.features.children():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n        for m in self.classifier.children():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform(m.weight)\n            elif isinstance(m, nn.BatchNorm1d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n                \n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        \n        return x     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3227d3f557f1770c43721ea7fc9bfc11d313e177","_cell_guid":"5b36bb2e-f4ce-4831-b829-0b737b88c014","trusted":true},"cell_type":"code","source":"model = Net()\n\noptimizer = optim.Adam(model.parameters(), lr=0.003)\n\ncriterion = nn.CrossEntropyLoss()\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"397c6aa3d575226f3fb0c8a3a8a30889bcd8e255","_cell_guid":"be618460-65ae-4dfc-b106-1970019b984f","trusted":true},"cell_type":"code","source":"def train(epoch):\n    model.train()\n    exp_lr_scheduler.step()\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = Variable(data), Variable(target)\n        \n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        \n        loss.backward()\n        optimizer.step()\n        \n        if (batch_idx + 1)% 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n                100. * (batch_idx + 1) / len(train_loader), loss.data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"977bf7d8ca46333bb53b7b44be40942d0e82572a","_cell_guid":"3901fd52-c016-4b7f-bcb4-80a2449b43f4","trusted":true},"cell_type":"code","source":"def evaluate(data_loader):\n    model.eval()\n    loss = 0\n    correct = 0\n    \n    for data, target in data_loader:\n        data, target = Variable(data, volatile=True), Variable(target)\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        output = model(data)\n        \n        loss += F.cross_entropy(output, target, size_average=False).data\n\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n    loss /= len(data_loader.dataset)\n        \n    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        loss, correct, len(data_loader.dataset),\n        100. * correct / len(data_loader.dataset)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ca8fe3ded9fcd5dc09350aff412d878eac0df6a","_cell_guid":"c7b3146c-0beb-438d-a8de-15f6afa11ba3","trusted":true},"cell_type":"code","source":"n_epochs = 3\n\nfor epoch in range(n_epochs):\n    train(epoch)\n    evaluate(train_loader)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f043414ac704967a9ab2b659fe5567a66796d6ba","_cell_guid":"3357ea6a-db51-4be7-b101-933720ad5fca"},"cell_type":"markdown","source":"## Prediction on Test Set","execution_count":null},{"metadata":{"_uuid":"9fdbe41834761b6b91cfe4eebdfc88ce29f0723e","_cell_guid":"e00a390b-0aaf-4119-926b-03ffe486e99d","trusted":true},"cell_type":"code","source":"def prediciton(data_loader):\n    model.eval()\n    test_pred = torch.LongTensor()\n    \n    for i, data in enumerate(data_loader):\n        data = Variable(data, volatile=True)\n        if torch.cuda.is_available():\n            data = data.cuda()\n            \n        output = model(data)\n        \n        pred = output.cpu().data.max(1, keepdim=True)[1]\n        test_pred = torch.cat((test_pred, pred), dim=0)\n        \n    return test_pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe47f6c8c7bdfe85779ebfcf7a74e361f3b7c8a0","_cell_guid":"c6cc74dc-8de0-403b-abed-3ead97f0348c","trusted":true},"cell_type":"code","source":"test_pred = prediciton(test_loader)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ef57831bbeeb792e7d3a847198f002ebe02f8a5","_cell_guid":"6de7f1ff-4c33-4b1e-9316-ac022ad0287d","trusted":true},"cell_type":"code","source":"out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n                      columns=['ImageId', 'Label'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"899374536c219a3b6208a4947046b6a46515f24b","_cell_guid":"b9422a68-66e5-4bc1-af9f-1d7d02576a34","trusted":true},"cell_type":"code","source":"out_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42b9c61e3462f471d9cae883880232882de0f21f","_cell_guid":"9f53df55-4569-4f11-a038-f54a1e200161","trusted":true},"cell_type":"code","source":"out_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}